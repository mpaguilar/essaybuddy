essay_txt = """## I Love Technology Hype!

One of the parts I love about tech hype is that it is very exciting. It's kind of like getting a lottery ticket. The fun isn't winning (unless you win :) ), the fun is thinking about winning. If you have no idea what something can do, then you can make up whatever you like - it can do anything!

Another part I love is finding out which of those claims ends up being true. They made fun of pets.com back in the day. Now I buy a good chunk of my pet supplies online. Heck, the stuff said about smartphones seems kind of prosaic considering how influential they are. Strange as it seems, there are people out there who use Bitcoin as currency, as a means of exchanging value.

Let's start off with the obvious objections: LLMs make mistakes. 

Hm. Yup. So do people. My plan for that is simple: I'll double check their work, and limit the work they do. 

A neat trick with an LLM is you can have it check your work. It's been great for improving my documentation. Writing for the A.I. has improved it for people, too, and I can ask it to check every revision. I didn't have it write this article, but I did have it critique it. This isn't my first draft.

I can enthusiastically recommend MS Edge using Copilot. There's a chat option to use only the current website as a source for information, so it is effectively searching the site for you. That has saved me hours of searching and summarizing documentation, complete with links to references. It has replaced searching with Google, clicking, reading, opening another tab, searching, clicking, reading...and so on. I check the work, and most of the time it's good.

That's something that the LLMs are good at: trawling and summarizing documentation, aka "Retrieval Augmentated Generation", aka "RAG". Expect your documentation vendor to add "OpenAPI endpoint compatible" to their list of features, as well as "omni-RAG" that promise to hook into all of your documentation sources and consolidate them.

I have a completely local setup that mostly works.
 - Open-WebUI
 - ollama/llama.cpp
 - SearXNG
 - Some custom prompts

It wasn't all that easy to get it all going, and there are definitely rough edges everywhere. I can't really recommend it unless you really like rabbit-holes. With that combo, I have a nice plain-language search engine for both the internet and my own docs. I've got a really good idea how to really scale it up and out, fairly inexpensively. The best thing OpenAI has done is create an "OpenAI API endpoint" that the other AI providers are cloning.

Now that it's all setup, I find myself using it differently than I do ChatGPT or any of its competitors, a little more in-depth. I'm more picky about the LLM model that I use, and much more picky about the prompts. It's the first setup around LLMs that truly felt like it was mine, built for me to do what I wanted to do. I'm generally pretty happy with it all, and I'd say that things have reached the "enthusiast" part of the hype cycle: accessible, but a bunch of work.
"""
